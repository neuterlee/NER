{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar las dependencias necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar las dependencias necesarias\n",
    "!pip install -U spacy scikit-learn\n",
    "!pip install ipywidgets\n",
    "!pip install spacy spacy-transformers\n",
    "!python -m spacy download es_dep_news_trf\n",
    "!pip install cupy-cuda12x\n",
    "\n",
    "# Instalar PyTorch (asegúrate de usar la versión adecuada para tu sistema)\n",
    "import os\n",
    "if os.system(\"nvidia-smi\") == 0:  # Detectar si hay GPU disponible\n",
    "    print(\"Instalando PyTorch con soporte para GPU...\")\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "else:\n",
    "    print(\"Instalando PyTorch para CPU...\")\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepara JSON para Spacy\n",
    "Este script convierte anotaciones de NER (Reconocimiento de Entidades Nombradas) en formato JSON \n",
    "a un formato compatible con spaCy para entrenamiento. Divide los datos en conjuntos de entrenamiento \n",
    "y validación, y guarda los resultados en archivos binarios.\n",
    "\n",
    "Cómo usar:\n",
    "1. Coloca un archivo JSON con las anotaciones en el mismo directorio donde se encuentra este script.\n",
    "2. Ejecuta el script.\n",
    "3. Los archivos de salida se guardarán en una carpeta llamada `annotations_dataset`.\n",
    "4. Si ocurre algún error durante la conversión, se registrará en un archivo de log llamado `train_file.txt`.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def get_spacy_doc(file, data, nlp):\n",
    "    \"\"\"\n",
    "    Convierte los datos en formato spaCy.\n",
    "    :param file: Archivo de log para registrar errores.\n",
    "    :param data: Datos de anotaciones.\n",
    "    :param nlp: Modelo de lenguaje spaCy.\n",
    "    :return: Objeto DocBin con los datos procesados.\n",
    "    \"\"\"\n",
    "    db = DocBin()\n",
    "    for text_data in data:\n",
    "        try:\n",
    "            text = text_data[0]\n",
    "            doc = nlp(text)\n",
    "            ents = []\n",
    "            for start, end, label in text_data[1]['entities']:\n",
    "                span = doc.char_span(start, end, label=label)\n",
    "                if span is not None:\n",
    "                    ents.append(span)\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "        except Exception as e:\n",
    "            file.write(f\"Error procesando el texto: {text}\\nError: {str(e)}\\n\\n\")\n",
    "    return db\n",
    "\n",
    "# Cargar el modelo de lenguaje en español\n",
    "nlp = spacy.blank(\"es\")\n",
    "\n",
    "# Buscar automáticamente un archivo JSON en el directorio actual\n",
    "json_files = [f for f in os.listdir(os.getcwd()) if f.endswith(\".json\")]\n",
    "if not json_files:\n",
    "    print(\"No se encontró ningún archivo JSON en el directorio actual.\")\n",
    "    exit()\n",
    "\n",
    "# Seleccionar el primer archivo JSON encontrado\n",
    "input_file = json_files[0]\n",
    "print(f\"Archivo JSON encontrado: {input_file}\")\n",
    "\n",
    "# Cargar las anotaciones desde el archivo JSON\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Obtener la lista de anotaciones\n",
    "annotations = data['annotations']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "train_data, test_data = train_test_split(annotations, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear los directorios de salida si no existen\n",
    "os.makedirs(\"annotations_dataset\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Generar nombres relevantes para los archivos\n",
    "log_file_path = os.path.join(\"logs\", \"train_file_log.txt\")\n",
    "train_output_path = os.path.join(\"annotations_dataset\", \"train.spacy\")\n",
    "valid_output_path = os.path.join(\"annotations_dataset\", \"valid.spacy\")\n",
    "\n",
    "# Abrir el archivo de log para registrar errores\n",
    "with open(log_file_path, 'w') as error_file:\n",
    "    # Crear y guardar los datos de entrenamiento\n",
    "    print(f\"Convirtiendo {len(train_data)} ejemplos de entrenamiento...\")\n",
    "    train_db = get_spacy_doc(error_file, train_data, nlp)\n",
    "    train_db.to_disk(train_output_path)\n",
    "    \n",
    "    # Crear y guardar los datos de validación\n",
    "    print(f\"Convirtiendo {len(test_data)} ejemplos de validación...\")\n",
    "    test_db = get_spacy_doc(error_file, test_data, nlp)\n",
    "    test_db.to_disk(valid_output_path)\n",
    "\n",
    "print(\"¡Finalizado! Se crearon:\")\n",
    "print(f\"- Datos de entrenamiento: {len(train_data)} ejemplos\")\n",
    "print(f\"- Datos de validación: {len(test_data)} ejemplos\")\n",
    "print(f\"Archivos guardados en la carpeta 'annotations_dataset/'.\")\n",
    "print(f\"Archivo de log guardado en: {log_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifica anotaciones antes de entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy debug data config.cfg --paths.train annotations_dataset/train.spacy --paths.dev annotations_dataset/valid.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecuta entrenamiento\n",
    "### Training Parameters (config.cfg)\n",
    "\n",
    "- `--max-epochs`: Maximum number of training epochs\n",
    "- `--batch-size`: Batch size for training\n",
    "- `--eval-frequency`: How often to evaluate on validation set\n",
    "- `--patience`: Early stopping patience\n",
    "- `--dropout`: Dropout rate during training\n",
    "\n",
    "## Output\n",
    "\n",
    "The training will create:\n",
    "- `output/model-best`: Best model based on validation scores\n",
    "- `output/model-last`: Last model state\n",
    "- Training logs with metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train config.cfg --output ./output --gpu-id 0 --paths.train annotations_dataset/train.spacy --paths.dev annotations_dataset/valid.spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
